{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!apt-get install openjdk-21-jre-headless -qq > /dev/null\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-21-openjdk-amd64\"\n",
        "!update-alternatives --set java /usr/lib/jvm/java-21-openjdk-amd64/bin/java\n",
        "!java -version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6EYbTMlQYQY3",
        "outputId": "9b17d4f5-7a53-419c-ba2b-179d79a58854"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "openjdk version \"21.0.5\" 2024-10-15\n",
            "OpenJDK Runtime Environment (build 21.0.5+11-Ubuntu-1ubuntu122.04)\n",
            "OpenJDK 64-Bit Server VM (build 21.0.5+11-Ubuntu-1ubuntu122.04, mixed mode, sharing)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "LC9vxWelQBXk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7a90218-738c-452a-a3e9-2b74193d635d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to the Information Retrieval System!\n",
            "Enter your query or type 'exit' to quit.\n",
            "\n",
            "Your query: telemarketer protection\n",
            "Running query: telemarketer protection\n",
            "\n",
            "Top Search Results:\n",
            "0.  AT&T, MCI SETTLE SUITS INVOLVING THEFT OF CUSTOMERS; COMMUNICATIONS: THE FIRMS ACCUSED EACH OTHER OF SWITCHING CONSUMERS WITHOUT THEIR CONSENT. BOTH NOW WANT THE FCC TO SET CONDUCT STANDARDS. \n",
            "1.  FT 18 JUN 92 / Telecommunications In Business (3): Area with high potential -Telemarketing \n",
            "2. \n",
            "3. \n",
            "4.  3 MEN CONVICTED IN $5-MILLION TELEMARKETING SCAM \n",
            "5.  'BOILER ROOM' CON ARTISTS USE CRACKS IN LAW \n",
            "6.  MAIL FRAUD COUNTS FILED AGAINST BREA MAN \n",
            "7.  STIFFER SENTENCES FOR CON MEN CHEER FRAUD TASK FORCE LEADERS \n",
            "8.  CINCINNATI BELL BUYS TELEMARKETING FIRM \n",
            "9.  VIEWPOINTS; TELEPHONE TECHNOLOGY VS. PRIVACY \n",
            "\n",
            "Relevant Terms Extracted:\n",
            "telemarketers\n",
            "ratepayers\n",
            "scam\n",
            "defrauded\n",
            "boiler\n",
            "\n",
            "Follow-up Query: telemarketer protection telemarketers ratepayers scam\n",
            "\n",
            "Extracted Keywords:\n",
            "telemarketer, protection\n",
            "\n",
            "Formatted Response:\n",
            "Your query: 'telemarketer protection'\n",
            "\n",
            "Based on your query, here are some relevant terms that might help refine your search:\n",
            "1. telemarketers (relevance score: 1.00)\n",
            "2. ratepayers (relevance score: 1.00)\n",
            "3. scam (relevance score: 1.00)\n",
            "4. defrauded (relevance score: 1.00)\n",
            "5. boiler (relevance score: 1.00)\n",
            "\n",
            "Keywords extracted from your query:\n",
            "telemarketer, protection\n",
            "\n",
            "Would you like to refine your search using any of these terms or keywords?\n",
            "\n",
            "Would you like to refine your search? (yes/no): telemarketer protection telemarketers ratepayers scam\n",
            "\n",
            "Your query: telemarketer protection telemarketers ratepayers scam\n",
            "Running query: telemarketer protection telemarketers ratepayers scam\n",
            "\n",
            "Top Search Results:\n",
            "0.  3 MEN CONVICTED IN $5-MILLION TELEMARKETING SCAM \n",
            "1. \n",
            "2.  O.C. SWINDLERS DETAIL PHONE SCAMS FOR PANEL \n",
            "3.  'BOILER ROOM' CON ARTISTS USE CRACKS IN LAW \n",
            "4.  CONSUMER VIEWS: TELEPHONE SCAMS -- A BAD CONNECTION \n",
            "5.  'BOILER ROOMS' PREY ON STAFF OF DISTANT FIRMS \n",
            "6.  LOCAL; 10 ARRESTED IN BIGGEST-EVER BUST OF BOILER-ROOM INVESTMENT SCAMS \n",
            "7.  AT&T, MCI SETTLE SUITS INVOLVING THEFT OF CUSTOMERS; COMMUNICATIONS: THE FIRMS ACCUSED EACH OTHER OF SWITCHING CONSUMERS WITHOUT THEIR CONSENT. BOTH NOW WANT THE FCC TO SET CONDUCT STANDARDS. \n",
            "8.  PERSONAL FINANCE / BILL SING: 'BOILER ROOMS' STILL DRAW THE NAIVE \n",
            "9.  FT 18 JUN 92 / Telecommunications In Business (3): Area with high potential -Telemarketing \n",
            "\n",
            "Relevant Terms Extracted:\n",
            "telemarketing\n",
            "scam\n",
            "mooches\n",
            "boiler\n",
            "bilked\n",
            "\n",
            "Follow-up Query: telemarketer protection telemarketers ratepayers scam telemarketing scam mooches\n",
            "\n",
            "Extracted Keywords:\n",
            "telemarketer, protection, telemarketers, ratepayers, scam\n",
            "\n",
            "Formatted Response:\n",
            "Your query: 'telemarketer protection telemarketers ratepayers scam'\n",
            "\n",
            "Based on your query, here are some relevant terms that might help refine your search:\n",
            "1. telemarketing (relevance score: 1.00)\n",
            "2. scam (relevance score: 1.00)\n",
            "3. mooches (relevance score: 1.00)\n",
            "4. boiler (relevance score: 1.00)\n",
            "5. bilked (relevance score: 1.00)\n",
            "\n",
            "Keywords extracted from your query:\n",
            "telemarketer, protection, telemarketers, ratepayers, scam\n",
            "\n",
            "Would you like to refine your search using any of these terms or keywords?\n",
            "\n",
            "Would you like to refine your search? (yes/no): no\n",
            "\n",
            "Your query: exit\n",
            "Thank you for using the Information Retrieval System!\n"
          ]
        }
      ],
      "source": [
        "import pyserini\n",
        "from pyserini.search.lucene import LuceneSearcher\n",
        "from pyserini.index import LuceneIndexReader\n",
        "from pyserini.search import get_topics\n",
        "from IPython.core.display import display, HTML\n",
        "import heapq\n",
        "import re\n",
        "from typing import List, Tuple\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import requests\n",
        "import math\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "NUM_TERMS = 10\n",
        "\n",
        "nltk.download('punkt', quiet=True)\n",
        "nltk.download('punkt_tab', quiet=True)\n",
        "nltk.download('stopwords', quiet=True)\n",
        "\n",
        "def initialize_model(index_path: str) -> Tuple[LuceneSearcher, LuceneIndexReader]:\n",
        "    searcher = LuceneSearcher.from_prebuilt_index(index_path)\n",
        "    reader = LuceneIndexReader.from_prebuilt_index(index_path)\n",
        "    return searcher, reader\n",
        "\n",
        "def generate_token_mapping(m: dict, docid: str, doc_vec: dict, reader: LuceneIndexReader) -> dict:\n",
        "    doc = reader.doc(docid).raw().lower()\n",
        "    for word in re.split(r'\\s+', doc):\n",
        "        analyzed = reader.analyze(word)\n",
        "        for t in doc_vec:\n",
        "            if t in analyzed:\n",
        "                word = re.sub(r'\\W+', '', word)\n",
        "                if t not in m:\n",
        "                  m[t] = word\n",
        "\n",
        "def get_doc_title(docid: str, reader: LuceneIndexReader) -> str:\n",
        "    soup = BeautifulSoup(reader.doc(docid).raw(), 'html.parser')\n",
        "    try:\n",
        "      headline = soup.find(\"headline\").get_text()\n",
        "      headline = re.sub(r'\\s+', ' ', headline)\n",
        "    except AttributeError:\n",
        "      headline = \"\"\n",
        "    return headline\n",
        "\n",
        "def get_relevant_terms(query: str, n: int, searcher: LuceneSearcher, reader: LuceneIndexReader) -> List[Tuple[float, str]]:\n",
        "    hits = searcher.search(query, n)\n",
        "    all_terms = {}\n",
        "    m = {}\n",
        "    appearances = {}\n",
        "    titles = []\n",
        "    for i in hits:\n",
        "        titles.append(get_doc_title(i.docid, reader))\n",
        "        doc_vec = reader.get_document_vector(i.docid)\n",
        "        generate_token_mapping(m, i.docid, doc_vec, reader)\n",
        "        for t in doc_vec:\n",
        "            tf = doc_vec[t] / len(doc_vec)\n",
        "            idf = reader.stats()['documents'] / (reader.get_term_counts(t, analyzer=None)[0] + 1)\n",
        "            tf_idf = math.log(tf * idf) if (tf * idf) > 0 else 0\n",
        "            if m[t] not in all_terms:\n",
        "                all_terms[m[t]] = tf_idf\n",
        "            else:\n",
        "                all_terms[m[t]] += tf_idf\n",
        "            # track appearances to add a document appearance threshold\n",
        "            if t not in appearances:\n",
        "                appearances[t] = 1\n",
        "            else:\n",
        "                appearances[t] += 1\n",
        "    # penalize terms that only occur in one document\n",
        "    for t in appearances:\n",
        "        if appearances[t] < 2:\n",
        "            all_terms[m[t]] = 0\n",
        "    most_rel = heapq.nlargest(n, all_terms, key=all_terms.get)\n",
        "    return titles, most_rel\n",
        "\n",
        "\n",
        "def evaluate_follow_up_query(query: str, relevant_terms: List[str], searcher: LuceneSearcher, reader: LuceneIndexReader, k: int = 10) -> float:\n",
        "    enhanced_query = f\"{query} {' '.join(relevant_terms)}\"\n",
        "    hits = searcher.search(enhanced_query, k)\n",
        "    return sum((i + 1) / len(hits) for i in range(len(hits))) / len(hits)\n",
        "\n",
        "def extract_keywords_rake(text: str, n: int = 5) -> List[str]:\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    word_scores = {}\n",
        "\n",
        "    words = word_tokenize(text.lower())\n",
        "    for word in words:\n",
        "        if word not in stop_words and word.isalnum():\n",
        "            if word not in word_scores:\n",
        "                word_scores[word] = 1\n",
        "            else:\n",
        "                word_scores[word] += 1\n",
        "\n",
        "    return sorted(word_scores, key=word_scores.get, reverse=True)[:n]\n",
        "\n",
        "def format_response(query: str, relevant_terms: List[Tuple[float, str]], keywords: List[str]) -> str:\n",
        "    response = f\"Your query: '{query}'\\n\\n\"\n",
        "    response += \"Based on your query, here are some relevant terms that might help refine your search:\\n\"\n",
        "    for i, (score, term) in enumerate(relevant_terms[:5], 1):\n",
        "        response += f\"{i}. {term} (relevance score: {score:.2f})\\n\"\n",
        "\n",
        "    response += \"\\nKeywords extracted from your query:\\n\"\n",
        "    response += \", \".join(keywords)\n",
        "\n",
        "    response += \"\\n\\nWould you like to refine your search using any of these terms or keywords?\"\n",
        "    return response\n",
        "\n",
        "def google_search_api(query: str, api_key: str, num_results: int = 10):\n",
        "    base_url = \"https://www.searchapi.io/api/v1/search\"\n",
        "    params = {\n",
        "        \"q\": query,\n",
        "        \"num\": num_results,\n",
        "        \"engine\": \"google\",\n",
        "        \"api_key\": api_key\n",
        "    }\n",
        "\n",
        "    response = requests.get(base_url, params=params)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        data = response.json()\n",
        "        results = []\n",
        "        if \"organic_results\" in data:\n",
        "            for result in data[\"organic_results\"]:\n",
        "                results.append({\n",
        "                    \"title\": result.get(\"title\", \"No Title\"),\n",
        "                    \"link\": result.get(\"link\", \"No Link\")\n",
        "                })\n",
        "        return results\n",
        "    else:\n",
        "        print(f\"Error: {response.status_code} - {response.text}\")\n",
        "        return []\n",
        "\n",
        "def run_model(query: str, s: LuceneSearcher, r: LuceneIndexReader):\n",
        "    print(f\"Running query: {query}\")\n",
        "    titles, relevant_terms = get_relevant_terms(query, NUM_TERMS, s, r)\n",
        "    print(\"\\nTop Search Results:\")\n",
        "    for idx, t in enumerate(titles):\n",
        "        print(f\"{idx}. {t}\")\n",
        "    print(\"\\nRelevant Terms Extracted:\")\n",
        "    for term in relevant_terms[:5]:\n",
        "        print(term)\n",
        "    follow_up_query = f\"{query} {' '.join(relevant_terms[:3])}\"\n",
        "    print(f\"\\nFollow-up Query: {follow_up_query}\")\n",
        "\n",
        "    keywords = extract_keywords_rake(query)\n",
        "    print(\"\\nExtracted Keywords:\")\n",
        "    print(\", \".join(keywords))\n",
        "\n",
        "    formatted_response = format_response(query, [(1.0, term) for term in relevant_terms[:5]], keywords)\n",
        "    print(\"\\nFormatted Response:\")\n",
        "    print(formatted_response)\n",
        "\n",
        "\n",
        "\n",
        "def run_model_with_google_api(query: str, api_key: str):\n",
        "    print(f\"Running query: {query}\")\n",
        "\n",
        "    search_results = google_search_api(query, api_key)\n",
        "\n",
        "    if search_results:\n",
        "        print(\"\\nTop Search Results:\")\n",
        "        for idx, result in enumerate(search_results, start=1):\n",
        "            print(f\"{idx}. {result['title']} - {result['link']}\")\n",
        "\n",
        "        relevant_terms = [result['title'] for result in search_results]\n",
        "\n",
        "        print(\"\\nRelevant Terms Extracted:\")\n",
        "        for term in relevant_terms[:5]:\n",
        "            print(term)\n",
        "\n",
        "        follow_up_query = f\"{query} {' '.join(relevant_terms[:3])}\"\n",
        "        print(f\"\\nFollow-up Query: {follow_up_query}\")\n",
        "\n",
        "        keywords = extract_keywords_rake(query)\n",
        "        print(\"\\nExtracted Keywords:\")\n",
        "        print(\", \".join(keywords))\n",
        "\n",
        "        formatted_response = format_response(query, [(1.0, term) for term in relevant_terms[:5]], keywords)\n",
        "        print(\"\\nFormatted Response:\")\n",
        "        print(formatted_response)\n",
        "    else:\n",
        "        print(\"No results returned from the Google Search API.\")\n",
        "\n",
        "\n",
        "def conversational_interface(api_key: str):\n",
        "    print(\"Welcome to the Information Retrieval System!\")\n",
        "    print(\"Enter your query or type 'exit' to quit.\")\n",
        "\n",
        "    s, r = initialize_model(\"robust04\")\n",
        "\n",
        "    while True:\n",
        "        query = input(\"\\nYour query: \")\n",
        "        if query.lower() == 'exit':\n",
        "            break\n",
        "\n",
        "        #run_model_with_google_api(query, api_key)\n",
        "        run_model(query, s, r)\n",
        "\n",
        "        refine = input(\"\\nWould you like to refine your search? (yes/no): \")\n",
        "        if refine.lower() == 'yes':\n",
        "            refined_query = input(\"Enter your refined query: \")\n",
        "            #run_model_with_google_api(refined_query, api_key)\n",
        "            run_model(refined_query)\n",
        "\n",
        "    print(\"Thank you for using the Information Retrieval System!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    API_KEY = API_KEY = \"EKU2jbjfUzRv2uWRTZGSEpyk\"  # Replace with your actual API key\n",
        "    conversational_interface(API_KEY)\n"
      ]
    }
  ]
}