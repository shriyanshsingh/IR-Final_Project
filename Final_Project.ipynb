{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!apt-get install openjdk-21-jre-headless -qq > /dev/null\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-21-openjdk-amd64\"\n",
        "!update-alternatives --set java /usr/lib/jvm/java-21-openjdk-amd64/bin/java\n",
        "!java -version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6EYbTMlQYQY3",
        "outputId": "effc811a-c515-49d4-e7cf-c026253f9d7c"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "^C\n",
            "openjdk version \"21.0.5\" 2024-10-15\n",
            "OpenJDK Runtime Environment (build 21.0.5+11-Ubuntu-1ubuntu122.04)\n",
            "OpenJDK 64-Bit Server VM (build 21.0.5+11-Ubuntu-1ubuntu122.04, mixed mode, sharing)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "LC9vxWelQBXk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd8009d6-b594-4b8e-bb0c-344fba0a8b2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to the Information Retrieval System!\n",
            "Enter 'custom' to use our model or 'google' to use the google API\n",
            "Mode:google\n",
            "Enter your query or type 'exit' to quit.\n",
            "\n",
            "Your query: california whale watching\n",
            "Running query: california whale watching\n",
            "\n",
            "Top Search Results:\n",
            "1. The Best Places to Go Whale Watching in California - https://www.travelandleisure.com/trip-ideas/nature-travel/where-to-go-whale-watching-california\n",
            "2. Southern California Whale Watching Tours - https://newportwhales.com/california_Whale_Watch.html\n",
            "3. The Top 8 Places for Whale Watching in California - https://www.visitcalifornia.com/experience/top-places-whale-watching-california/\n",
            "4. Monterey Bay Whale Watch - Whale Watching Trips - https://montereybaywhalewatch.com/\n",
            "5. Whale Watching in San Diego, CA — Book Your Trip Now! - https://sdwhalewatch.com/\n",
            "6. Top Five Whale Watching Destinations in California - https://danawharf.com/blog/top-five-whale-watching-destinations-in-california/\n",
            "7. THE TOP 10 California Whale Watching Tours (w/Prices) - https://www.viator.com/California-tours/Dolphin-and-Whale-Watching/d272-g3-c77\n",
            "\n",
            "Relevant Terms Extracted:\n",
            "The Best Places to Go Whale Watching in California\n",
            "Southern California Whale Watching Tours\n",
            "The Top 8 Places for Whale Watching in California\n",
            "Monterey Bay Whale Watch - Whale Watching Trips\n",
            "Whale Watching in San Diego, CA — Book Your Trip Now!\n",
            "\n",
            "Follow-up Query: california whale watching The Best Places to Go Whale Watching in California Southern California Whale Watching Tours The Top 8 Places for Whale Watching in California\n",
            "\n",
            "Extracted Keywords:\n",
            "california, whale, watching\n",
            "\n",
            "Formatted Response:\n",
            "Your query: 'california whale watching'\n",
            "\n",
            "Based on your query, here are some relevant terms that might help refine your search:\n",
            "1. The Best Places to Go Whale Watching in California (relevance score: 1.00)\n",
            "2. Southern California Whale Watching Tours (relevance score: 1.00)\n",
            "3. The Top 8 Places for Whale Watching in California (relevance score: 1.00)\n",
            "4. Monterey Bay Whale Watch - Whale Watching Trips (relevance score: 1.00)\n",
            "5. Whale Watching in San Diego, CA — Book Your Trip Now! (relevance score: 1.00)\n",
            "\n",
            "Keywords extracted from your query:\n",
            "california, whale, watching\n",
            "Enter 'custom' to use our model or 'google' to use the google API\n",
            "Mode:custom\n",
            "Enter your query or type 'exit' to quit.\n",
            "\n",
            "Your query: california whale watching\n",
            "Running query: california whale watching\n",
            "\n",
            "Top Search Results:\n",
            "0.  WATERY FIELD TRIP; 29 OCEANGOING 3RD-GRADERS OVERCOME SEASICKNESS AND WATCH MIGRATING CALIFORNIA GRAY WHALES \n",
            "1.  AROUND THE SOUTH BAY: YEARLY VIGIL BEGINS AS WHALES PASS LOCAL WATERS ON 6,000-MILE MIGRATION. \n",
            "2.  WHALES FEW AT FESTIVAL, BUT WHO NOTICED? \n",
            "3.  MAN AND WHALES: JUST TOO CLOSE FOR COMFORT?; NATURE: HUMANS MAY BE DRIVING HUMPBACKS FROM BREEDING GROUNDS. A U.S. AGENCY WEIGHS GUARANTEEING THE MAMMALS 100 YARDS OF PRIVACY. \n",
            "4.  ON THE WATERFRONT: GROUP WORKS TO REGULATE WHALE WATCHING \n",
            "5.  WATCH THOSE WHALES; UP AND DOWN THE COAST, EXCURSIONS AND WORKSHOPS ABOUND \n",
            "6.  FT 10 SEP 94 / Travel: Chasing a tail shot - Practical Traveller \n",
            "7.  SCIENCE CALENDAR: SCIENCE / MEDICINE; MIGRATING WHALES ARE TOPICS OF TOURS, TALKS \n",
            "8.  TRIP OF THE WEEK: A GRAY WHALE OF A TALE \n",
            "9.  OUTDOORS; THERE'S SO MUCH TO TAKE IN; WHALES: IN WATERS 600 MILES SOUTH OF SAN DIEGO, KAYAKERS MARVEL AT THE SIGHT OF THE GIANT MAMMALS, WHO ARE INCREDIBLY TOLERANT OF THE INTRUSION. \n",
            "\n",
            "Relevant Terms Extracted:\n",
            "whales\n",
            "cetacean\n",
            "baja\n",
            "humpbacks\n",
            "sportfishing\n",
            "\n",
            "Follow-up Query: california whale watching whales cetacean baja\n",
            "\n",
            "Extracted Keywords:\n",
            "california, whale, watching\n",
            "\n",
            "Formatted Response:\n",
            "Your query: 'california whale watching'\n",
            "\n",
            "Based on your query, here are some relevant terms that might help refine your search:\n",
            "1. whales (relevance score: 1.00)\n",
            "2. cetacean (relevance score: 1.00)\n",
            "3. baja (relevance score: 1.00)\n",
            "4. humpbacks (relevance score: 1.00)\n",
            "5. sportfishing (relevance score: 1.00)\n",
            "\n",
            "Keywords extracted from your query:\n",
            "california, whale, watching\n",
            "Enter 'custom' to use our model or 'google' to use the google API\n",
            "Mode:exit\n",
            "Thank you for using the Information Retrieval System!\n"
          ]
        }
      ],
      "source": [
        "import pyserini\n",
        "from pyserini.search.lucene import LuceneSearcher\n",
        "from pyserini.index import LuceneIndexReader\n",
        "from pyserini.search import get_topics\n",
        "from IPython.core.display import display, HTML\n",
        "import heapq\n",
        "import re\n",
        "from typing import List, Tuple\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import requests\n",
        "import math\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.request import urlopen\n",
        "from pyserini.search import get_topics\n",
        "from tqdm import tqdm\n",
        "\n",
        "NUM_TERMS = 10\n",
        "\n",
        "nltk.download('punkt', quiet=True)\n",
        "nltk.download('punkt_tab', quiet=True)\n",
        "nltk.download('stopwords', quiet=True)\n",
        "\n",
        "def initialize_model(index_path: str) -> Tuple[LuceneSearcher, LuceneIndexReader]:\n",
        "    searcher = LuceneSearcher.from_prebuilt_index(index_path)\n",
        "    reader = LuceneIndexReader.from_prebuilt_index(index_path)\n",
        "    return searcher, reader\n",
        "\n",
        "def generate_token_mapping(m: dict, docid: str, doc_vec: dict, reader: LuceneIndexReader) -> dict:\n",
        "    doc = reader.doc(docid).raw().lower()\n",
        "    for word in re.split(r'\\s+', doc):\n",
        "        analyzed = reader.analyze(word)\n",
        "        for t in doc_vec:\n",
        "            if t in analyzed:\n",
        "                word = re.sub(r'\\W+', '', word)\n",
        "                if t not in m:\n",
        "                  m[t] = word\n",
        "\n",
        "def get_doc_title(docid: str, reader: LuceneIndexReader) -> str:\n",
        "    soup = BeautifulSoup(reader.doc(docid).raw(), 'html.parser')\n",
        "    try:\n",
        "      headline = soup.find(\"headline\").get_text()\n",
        "      headline = re.sub(r'\\s+', ' ', headline)\n",
        "    except AttributeError:\n",
        "      headline = \"NO HEADLINE\"\n",
        "    return headline\n",
        "\n",
        "def get_relevant_terms(query: str, n: int, searcher: LuceneSearcher, reader: LuceneIndexReader) -> List[Tuple[float, str]]:\n",
        "    hits = searcher.search(query, n)\n",
        "    all_terms = {}\n",
        "    m = {}\n",
        "    appearances = {}\n",
        "    titles = []\n",
        "    for i in hits:\n",
        "        titles.append(get_doc_title(i.docid, reader))\n",
        "        doc_vec = reader.get_document_vector(i.docid)\n",
        "        generate_token_mapping(m, i.docid, doc_vec, reader)\n",
        "        for t in doc_vec:\n",
        "            tf = doc_vec[t] / len(doc_vec)\n",
        "            idf = reader.stats()['documents'] / (reader.get_term_counts(t, analyzer=None)[0] + 1)\n",
        "            tf_idf = math.log(tf * idf) if (tf * idf) > 0 else 0\n",
        "            if t not in m:\n",
        "              continue\n",
        "            if m[t] not in all_terms:\n",
        "                all_terms[m[t]] = tf_idf\n",
        "            else:\n",
        "                all_terms[m[t]] += tf_idf\n",
        "            # track appearances to add a document appearance threshold\n",
        "            if t not in appearances:\n",
        "                appearances[t] = 1\n",
        "            else:\n",
        "                appearances[t] += 1\n",
        "    # penalize terms that only occur in one document\n",
        "    for t in appearances:\n",
        "        if appearances[t] < 2:\n",
        "            all_terms[m[t]] = 0\n",
        "    most_rel = heapq.nlargest(n, all_terms, key=all_terms.get)\n",
        "    return titles, most_rel\n",
        "\n",
        "def extract_keywords_rake(text: str, n: int = 5) -> List[str]:\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    word_scores = {}\n",
        "\n",
        "    words = word_tokenize(text.lower())\n",
        "    for word in words:\n",
        "        if word not in stop_words and word.isalnum():\n",
        "            if word not in word_scores:\n",
        "                word_scores[word] = 1\n",
        "            else:\n",
        "                word_scores[word] += 1\n",
        "\n",
        "    return sorted(word_scores, key=word_scores.get, reverse=True)[:n]\n",
        "\n",
        "def format_response(query: str, relevant_terms: List[Tuple[float, str]], keywords: List[str]) -> str:\n",
        "    response = f\"Your query: '{query}'\\n\\n\"\n",
        "    response += \"Based on your query, here are some relevant terms that might help refine your search:\\n\"\n",
        "    for i, (score, term) in enumerate(relevant_terms[:5], 1):\n",
        "        response += f\"{i}. {term} (relevance score: {score:.2f})\\n\"\n",
        "\n",
        "    response += \"\\nKeywords extracted from your query:\\n\"\n",
        "    response += \", \".join(keywords)\n",
        "\n",
        "    return response\n",
        "\n",
        "def google_search_api(query: str, api_key: str, num_results: int = 10):\n",
        "    base_url = \"https://www.searchapi.io/api/v1/search\"\n",
        "    params = {\n",
        "        \"q\": query,\n",
        "        \"num\": num_results,\n",
        "        \"engine\": \"google\",\n",
        "        \"api_key\": api_key\n",
        "    }\n",
        "\n",
        "    response = requests.get(base_url, params=params)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        data = response.json()\n",
        "        results = []\n",
        "        if \"organic_results\" in data:\n",
        "            for result in data[\"organic_results\"]:\n",
        "                results.append({\n",
        "                    \"title\": result.get(\"title\", \"No Title\"),\n",
        "                    \"link\": result.get(\"link\", \"No Link\")\n",
        "                })\n",
        "        return results\n",
        "    else:\n",
        "        print(f\"Error: {response.status_code} - {response.text}\")\n",
        "        return []\n",
        "\n",
        "def run_model(query: str, s: LuceneSearcher, r: LuceneIndexReader):\n",
        "    print(f\"Running query: {query}\")\n",
        "    titles, relevant_terms = get_relevant_terms(query, NUM_TERMS, s, r)\n",
        "    print(\"\\nTop Search Results:\")\n",
        "    for idx, t in enumerate(titles):\n",
        "        print(f\"{idx}. {t}\")\n",
        "    print(\"\\nRelevant Terms Extracted:\")\n",
        "    for term in relevant_terms[:5]:\n",
        "        print(term)\n",
        "    follow_up_query = f\"{query} {' '.join(relevant_terms[:3])}\"\n",
        "    print(f\"\\nFollow-up Query: {follow_up_query}\")\n",
        "\n",
        "    keywords = extract_keywords_rake(query)\n",
        "    print(\"\\nExtracted Keywords:\")\n",
        "    print(\", \".join(keywords))\n",
        "\n",
        "    formatted_response = format_response(query, [(1.0, term) for term in relevant_terms[:5]], keywords)\n",
        "    print(\"\\nFormatted Response:\")\n",
        "    print(formatted_response)\n",
        "\n",
        "\n",
        "\n",
        "def run_model_with_google_api(query: str, api_key: str):\n",
        "    print(f\"Running query: {query}\")\n",
        "\n",
        "    search_results = google_search_api(query, api_key)\n",
        "\n",
        "    if search_results:\n",
        "        print(\"\\nTop Search Results:\")\n",
        "        for idx, result in enumerate(search_results, start=1):\n",
        "            print(f\"{idx}. {result['title']} - {result['link']}\")\n",
        "\n",
        "        relevant_terms = [result['title'] for result in search_results]\n",
        "\n",
        "        print(\"\\nRelevant Terms Extracted:\")\n",
        "        for term in relevant_terms[:5]:\n",
        "            print(term)\n",
        "\n",
        "        follow_up_query = f\"{query} {' '.join(relevant_terms[:3])}\"\n",
        "        print(f\"\\nFollow-up Query: {follow_up_query}\")\n",
        "\n",
        "        keywords = extract_keywords_rake(query)\n",
        "        print(\"\\nExtracted Keywords:\")\n",
        "        print(\", \".join(keywords))\n",
        "\n",
        "        formatted_response = format_response(query, [(1.0, term) for term in relevant_terms[:5]], keywords)\n",
        "        print(\"\\nFormatted Response:\")\n",
        "        print(formatted_response)\n",
        "    else:\n",
        "        print(\"No results returned from the Google Search API.\")\n",
        "\n",
        "\n",
        "def conversational_interface(api_key: str):\n",
        "    print(\"Welcome to the Information Retrieval System!\")\n",
        "\n",
        "    s, r = initialize_model(\"robust04\")\n",
        "\n",
        "    while True:\n",
        "        mode = input(\"Enter \\'custom\\' to use our model or \\'google\\' to use the google API\\nMode:\")\n",
        "        while mode != 'google' and mode != 'custom':\n",
        "          if mode == 'exit':\n",
        "            break\n",
        "          print(\"Invalid mode. Please enter 'custom' or 'google'.\")\n",
        "          mode = input(\"Enter \\'custom\\' to use our model or \\'google\\' to use the google API\\nMode:\")\n",
        "        if mode == 'exit':\n",
        "          break\n",
        "\n",
        "        print(\"Enter your query or type 'exit' to quit.\")\n",
        "        query = input(\"\\nYour query: \")\n",
        "\n",
        "        if query.lower() == 'exit':\n",
        "            break\n",
        "        if mode == 'google':\n",
        "          run_model_with_google_api(query, api_key)\n",
        "        else:\n",
        "          run_model(query, s, r)\n",
        "\n",
        "    print(\"Thank you for using the Information Retrieval System!\")\n",
        "\n",
        "def evaluate_model():\n",
        "    s, r = initialize_model('robust04')\n",
        "    qfile = 'https://github.com/castorini/anserini-tools/blob/63ceeab1dd94c1221f29b931d868e8fab67cc25c/topics-and-qrels/qrels.robust04.txt?raw=true'\n",
        "    qrels = []\n",
        "    for line in urlopen(qfile):\n",
        "        qid, round, docid, score = line.strip().split()\n",
        "        qrels.append([int(qid), 0, docid.decode('UTF-8'), int(score)])\n",
        "    qrels = [line.strip().split() for line in urlopen(qfile)]\n",
        "    qrel_dict = {}\n",
        "    for q in qrels:\n",
        "      if int(q[3]) >= 1:\n",
        "        if int(q[0]) in qrel_dict:\n",
        "            qrel_dict[int(q[0])].add(q[2].decode('utf-8'))\n",
        "        else:\n",
        "            qrel_dict[int(q[0])] = set()\n",
        "            qrel_dict[int(q[0])].add(q[2].decode('utf-8'))\n",
        "    topics = get_topics('robust04')\n",
        "    topics = {k:topics[k] for k in list(topics.keys())[:100]}\n",
        "    difs = []\n",
        "    for t in tqdm(topics):\n",
        "      query = topics[t]['title']\n",
        "      acc_1 = MAP_100(t, query, s, qrel_dict)\n",
        "      _, rel_topics = get_relevant_terms(topics[t]['title'], NUM_TERMS, s, r)\n",
        "      refined = f\"{query} {' '.join(rel_topics)}\"\n",
        "      acc_2 = MAP_100(t, refined, s, qrel_dict)\n",
        "      difs.append(acc_2 - acc_1)\n",
        "    return sum(difs) / len(difs)\n",
        "\n",
        "\n",
        "def MAP_1000(t: int, query: str, searcher: LuceneSearcher, qrel: dict) -> float:\n",
        "    hits = searcher.search(query, 1000)\n",
        "    P = 0\n",
        "    rel = 0\n",
        "\n",
        "    relevant_docs = qrel.get(t, set())\n",
        "    for h, hit in enumerate(hits):\n",
        "        if hit.docid in relevant_docs:\n",
        "          rel += 1\n",
        "          P += (rel / (h + 1))\n",
        "    return P / rel if rel > 0 else 0\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    API_KEY = API_KEY = \"EKU2jbjfUzRv2uWRTZGSEpyk\"  # Replace with your actual API key\n",
        "    # to evaluate the model, uncomment this code.\n",
        "    # print(f\"\\nThe average change in MAP@1000 between normal and refined queries is {evaluate_model()}\")\n",
        "    conversational_interface(API_KEY)\n"
      ]
    }
  ]
}