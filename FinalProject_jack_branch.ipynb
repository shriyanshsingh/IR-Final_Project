{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!apt-get install openjdk-21-jre-headless -qq > /dev/null\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-21-openjdk-amd64\"\n",
        "!update-alternatives --set java /usr/lib/jvm/java-21-openjdk-amd64/bin/java\n",
        "!java -version"
      ],
      "metadata": {
        "id": "6EYbTMlQYQY3",
        "outputId": "9b17d4f5-7a53-419c-ba2b-179d79a58854",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "openjdk version \"21.0.5\" 2024-10-15\n",
            "OpenJDK Runtime Environment (build 21.0.5+11-Ubuntu-1ubuntu122.04)\n",
            "OpenJDK 64-Bit Server VM (build 21.0.5+11-Ubuntu-1ubuntu122.04, mixed mode, sharing)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "LC9vxWelQBXk",
        "outputId": "0ddc3d39-9c59-436e-8814-a0e9b26a70a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to the Information Retrieval System!\n",
            "Enter your query or type 'exit' to quit.\n",
            "Running query: whale watching California\n",
            "\n",
            "Top Search Results:\n",
            "0.  WATERY FIELD TRIP; 29 OCEANGOING 3RD-GRADERS OVERCOME SEASICKNESS AND WATCH MIGRATING CALIFORNIA GRAY WHALES \n",
            "1.  AROUND THE SOUTH BAY: YEARLY VIGIL BEGINS AS WHALES PASS LOCAL WATERS ON 6,000-MILE MIGRATION. \n",
            "2.  WHALES FEW AT FESTIVAL, BUT WHO NOTICED? \n",
            "3.  MAN AND WHALES: JUST TOO CLOSE FOR COMFORT?; NATURE: HUMANS MAY BE DRIVING HUMPBACKS FROM BREEDING GROUNDS. A U.S. AGENCY WEIGHS GUARANTEEING THE MAMMALS 100 YARDS OF PRIVACY. \n",
            "4.  ON THE WATERFRONT: GROUP WORKS TO REGULATE WHALE WATCHING \n",
            "5.  WATCH THOSE WHALES; UP AND DOWN THE COAST, EXCURSIONS AND WORKSHOPS ABOUND \n",
            "6.  FT 10 SEP 94 / Travel: Chasing a tail shot - Practical Traveller \n",
            "7.  SCIENCE CALENDAR: SCIENCE / MEDICINE; MIGRATING WHALES ARE TOPICS OF TOURS, TALKS \n",
            "8.  TRIP OF THE WEEK: A GRAY WHALE OF A TALE \n",
            "9.  OUTDOORS; THERE'S SO MUCH TO TAKE IN; WHALES: IN WATERS 600 MILES SOUTH OF SAN DIEGO, KAYAKERS MARVEL AT THE SIGHT OF THE GIANT MAMMALS, WHO ARE INCREDIBLY TOLERANT OF THE INTRUSION. \n",
            "\n",
            "Relevant Terms Extracted:\n",
            "whales\n",
            "cetacean\n",
            "baja\n",
            "humpbacks\n",
            "sportfishing\n",
            "\n",
            "Follow-up Query: whale watching California whales cetacean baja\n",
            "\n",
            "Extracted Keywords:\n",
            "whale, watching, california\n",
            "\n",
            "Formatted Response:\n",
            "Your query: 'whale watching California'\n",
            "\n",
            "Based on your query, here are some relevant terms that might help refine your search:\n",
            "1. whales (relevance score: 1.00)\n",
            "2. cetacean (relevance score: 1.00)\n",
            "3. baja (relevance score: 1.00)\n",
            "4. humpbacks (relevance score: 1.00)\n",
            "5. sportfishing (relevance score: 1.00)\n",
            "\n",
            "Keywords extracted from your query:\n",
            "whale, watching, california\n",
            "\n",
            "Would you like to refine your search using any of these terms or keywords?\n",
            "Thank you for using the Information Retrieval System!\n"
          ]
        }
      ],
      "source": [
        "import pyserini\n",
        "from pyserini.search.lucene import LuceneSearcher\n",
        "from pyserini.index import LuceneIndexReader\n",
        "from pyserini.search import get_topics\n",
        "from IPython.core.display import display, HTML\n",
        "import heapq\n",
        "import re\n",
        "from typing import List, Tuple\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import requests\n",
        "import math\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "NUM_TERMS = 10\n",
        "\n",
        "nltk.download('punkt', quiet=True)\n",
        "nltk.download('punkt_tab', quiet=True)\n",
        "nltk.download('stopwords', quiet=True)\n",
        "\n",
        "def initialize_model(index_path: str) -> Tuple[LuceneSearcher, LuceneIndexReader]:\n",
        "    searcher = LuceneSearcher.from_prebuilt_index(index_path)\n",
        "    reader = LuceneIndexReader.from_prebuilt_index(index_path)\n",
        "    return searcher, reader\n",
        "\n",
        "def generate_token_mapping(m: dict, docid: str, doc_vec: dict, reader: LuceneIndexReader) -> dict:\n",
        "    doc = reader.doc(docid).raw().lower()\n",
        "    for word in re.split(r'\\s+', doc):\n",
        "        analyzed = reader.analyze(word)\n",
        "        for t in doc_vec:\n",
        "            if t in analyzed:\n",
        "                word = re.sub(r'\\W+', '', word)\n",
        "                if t not in m:\n",
        "                  m[t] = word\n",
        "\n",
        "def get_doc_title(docid: str, reader: LuceneIndexReader) -> str:\n",
        "    soup = BeautifulSoup(reader.doc(docid).raw(), 'html.parser')\n",
        "    headline = soup.find(\"headline\").get_text()\n",
        "    headline = re.sub(r'\\s+', ' ', headline)\n",
        "    return headline\n",
        "\n",
        "def get_relevant_terms(query: str, n: int, searcher: LuceneSearcher, reader: LuceneIndexReader) -> List[Tuple[float, str]]:\n",
        "    hits = searcher.search(query, n)\n",
        "    all_terms = {}\n",
        "    m = {}\n",
        "    appearances = {}\n",
        "    titles = []\n",
        "    for i in hits:\n",
        "        titles.append(get_doc_title(i.docid, reader))\n",
        "        doc_vec = reader.get_document_vector(i.docid)\n",
        "        generate_token_mapping(m, i.docid, doc_vec, reader)\n",
        "        for t in doc_vec:\n",
        "            tf = doc_vec[t] / len(doc_vec)\n",
        "            idf = reader.stats()['documents'] / (reader.get_term_counts(t, analyzer=None)[0] + 1)\n",
        "            tf_idf = math.log(tf * idf) if (tf * idf) > 0 else 0\n",
        "            if m[t] not in all_terms:\n",
        "                all_terms[m[t]] = tf_idf\n",
        "            else:\n",
        "                all_terms[m[t]] += tf_idf\n",
        "            # track appearances to add a document appearance threshold\n",
        "            if t not in appearances:\n",
        "                appearances[t] = 1\n",
        "            else:\n",
        "                appearances[t] += 1\n",
        "    # penalize terms that only occur in one document\n",
        "    for t in appearances:\n",
        "        if appearances[t] < 2:\n",
        "            all_terms[m[t]] = 0\n",
        "    most_rel = heapq.nlargest(n, all_terms, key=all_terms.get)\n",
        "    return titles, most_rel\n",
        "\n",
        "\n",
        "def evaluate_follow_up_query(query: str, relevant_terms: List[str], searcher: LuceneSearcher, reader: LuceneIndexReader, k: int = 10) -> float:\n",
        "    enhanced_query = f\"{query} {' '.join(relevant_terms)}\"\n",
        "    hits = searcher.search(enhanced_query, k)\n",
        "    return sum((i + 1) / len(hits) for i in range(len(hits))) / len(hits)\n",
        "\n",
        "def extract_keywords_rake(text: str, n: int = 5) -> List[str]:\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    word_scores = {}\n",
        "\n",
        "    words = word_tokenize(text.lower())\n",
        "    for word in words:\n",
        "        if word not in stop_words and word.isalnum():\n",
        "            if word not in word_scores:\n",
        "                word_scores[word] = 1\n",
        "            else:\n",
        "                word_scores[word] += 1\n",
        "\n",
        "    return sorted(word_scores, key=word_scores.get, reverse=True)[:n]\n",
        "\n",
        "def format_response(query: str, relevant_terms: List[Tuple[float, str]], keywords: List[str]) -> str:\n",
        "    response = f\"Your query: '{query}'\\n\\n\"\n",
        "    response += \"Based on your query, here are some relevant terms that might help refine your search:\\n\"\n",
        "    for i, (score, term) in enumerate(relevant_terms[:5], 1):\n",
        "        response += f\"{i}. {term} (relevance score: {score:.2f})\\n\"\n",
        "\n",
        "    response += \"\\nKeywords extracted from your query:\\n\"\n",
        "    response += \", \".join(keywords)\n",
        "\n",
        "    response += \"\\n\\nWould you like to refine your search using any of these terms or keywords?\"\n",
        "    return response\n",
        "\n",
        "def google_search_api(query: str, api_key: str, num_results: int = 10):\n",
        "    base_url = \"https://www.searchapi.io/api/v1/search\"\n",
        "    params = {\n",
        "        \"q\": query,\n",
        "        \"num\": num_results,\n",
        "        \"engine\": \"google\",\n",
        "        \"api_key\": api_key\n",
        "    }\n",
        "\n",
        "    response = requests.get(base_url, params=params)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        data = response.json()\n",
        "        results = []\n",
        "        if \"organic_results\" in data:\n",
        "            for result in data[\"organic_results\"]:\n",
        "                results.append({\n",
        "                    \"title\": result.get(\"title\", \"No Title\"),\n",
        "                    \"link\": result.get(\"link\", \"No Link\")\n",
        "                })\n",
        "        return results\n",
        "    else:\n",
        "        print(f\"Error: {response.status_code} - {response.text}\")\n",
        "        return []\n",
        "\n",
        "def run_model(query: str, s: LuceneSearcher, r: LuceneIndexReader):\n",
        "    print(f\"Running query: {query}\")\n",
        "    titles, relevant_terms = get_relevant_terms(query, NUM_TERMS, s, r)\n",
        "    print(\"\\nTop Search Results:\")\n",
        "    for idx, t in enumerate(titles):\n",
        "        print(f\"{idx}. {t}\")\n",
        "    print(\"\\nRelevant Terms Extracted:\")\n",
        "    for term in relevant_terms[:5]:\n",
        "        print(term)\n",
        "    follow_up_query = f\"{query} {' '.join(relevant_terms[:3])}\"\n",
        "    print(f\"\\nFollow-up Query: {follow_up_query}\")\n",
        "\n",
        "    keywords = extract_keywords_rake(query)\n",
        "    print(\"\\nExtracted Keywords:\")\n",
        "    print(\", \".join(keywords))\n",
        "\n",
        "    formatted_response = format_response(query, [(1.0, term) for term in relevant_terms[:5]], keywords)\n",
        "    print(\"\\nFormatted Response:\")\n",
        "    print(formatted_response)\n",
        "\n",
        "\n",
        "\n",
        "def run_model_with_google_api(query: str, api_key: str):\n",
        "    print(f\"Running query: {query}\")\n",
        "\n",
        "    search_results = google_search_api(query, api_key)\n",
        "\n",
        "    if search_results:\n",
        "        print(\"\\nTop Search Results:\")\n",
        "        for idx, result in enumerate(search_results, start=1):\n",
        "            print(f\"{idx}. {result['title']} - {result['link']}\")\n",
        "\n",
        "        relevant_terms = [result['title'] for result in search_results]\n",
        "\n",
        "        print(\"\\nRelevant Terms Extracted:\")\n",
        "        for term in relevant_terms[:5]:\n",
        "            print(term)\n",
        "\n",
        "        follow_up_query = f\"{query} {' '.join(relevant_terms[:3])}\"\n",
        "        print(f\"\\nFollow-up Query: {follow_up_query}\")\n",
        "\n",
        "        keywords = extract_keywords_rake(query)\n",
        "        print(\"\\nExtracted Keywords:\")\n",
        "        print(\", \".join(keywords))\n",
        "\n",
        "        formatted_response = format_response(query, [(1.0, term) for term in relevant_terms[:5]], keywords)\n",
        "        print(\"\\nFormatted Response:\")\n",
        "        print(formatted_response)\n",
        "    else:\n",
        "        print(\"No results returned from the Google Search API.\")\n",
        "\n",
        "\n",
        "def conversational_interface(api_key: str):\n",
        "    print(\"Welcome to the Information Retrieval System!\")\n",
        "    print(\"Enter your query or type 'exit' to quit.\")\n",
        "\n",
        "    s, r = initialize_model(\"robust04\")\n",
        "\n",
        "    while True:\n",
        "        query = input(\"\\nYour query: \")\n",
        "        if query.lower() == 'exit':\n",
        "            break\n",
        "\n",
        "        #run_model_with_google_api(query, api_key)\n",
        "        run_model(query, s, r)\n",
        "\n",
        "        refine = input(\"\\nWould you like to refine your search? (yes/no): \")\n",
        "        if refine.lower() == 'yes':\n",
        "            refined_query = input(\"Enter your refined query: \")\n",
        "            run_model_with_google_api(refined_query, api_key)\n",
        "\n",
        "    print(\"Thank you for using the Information Retrieval System!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    API_KEY = API_KEY = \"EKU2jbjfUzRv2uWRTZGSEpyk\"  # Replace with your actual API key\n",
        "    conversational_interface(API_KEY)\n"
      ]
    }
  ]
}